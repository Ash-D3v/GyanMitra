{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============ CELL 1: Setup ============\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr tesseract-ocr-hin tesseract-ocr-urd poppler-utils\n",
        "!pip install --upgrade pip\n",
        "!pip install pytesseract pdf2image PyPDF2 pillow tqdm\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output folder\n",
        "import os\n",
        "output_folder = '/content/drive/MyDrive/ncert_processed'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(\"Output folder ready at:\", output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCU7-eHzuiAO",
        "outputId": "469d84c4-44b4-4b34-9131-28e1786c9e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-hin is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "tesseract-ocr-urd is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Mounted at /content/drive\n",
            "Output folder ready at: /content/drive/MyDrive/ncert_processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHxtlTbrpsF9"
      },
      "outputs": [],
      "source": [
        "# ============ CELL 2: OCR Microservice ============\n",
        "import os\n",
        "import json\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Dict\n",
        "from PyPDF2 import PdfReader\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "@dataclass\n",
        "class ExtractedText:\n",
        "    text: str\n",
        "    source_file: str\n",
        "    grade: int\n",
        "    subject: str\n",
        "    language: str\n",
        "    page_num: int\n",
        "    extraction_method: str\n",
        "    confidence: float = 1.0\n",
        "\n",
        "class OPEAOCRService:\n",
        "    def __init__(self, supported_languages: List[str] = None):\n",
        "        self.supported_languages = supported_languages or ['eng','hin','urd']\n",
        "        self.tesseract_config = '--oem 3 --psm 6'\n",
        "\n",
        "    def extract_from_pdf(self, pdf_path: str, metadata: Dict, dpi: int=200, use_confidence: bool=False) -> List[ExtractedText]:\n",
        "        # Try native PDF extraction\n",
        "        try:\n",
        "            data = self._extract_native_pdf(pdf_path, metadata)\n",
        "            if data and len(data[0].text) > 100:\n",
        "                print(f\"✓ Native extraction successful: {pdf_path}\")\n",
        "                return data\n",
        "        except Exception as e:\n",
        "            print(f\"Native extraction failed: {e}\")\n",
        "\n",
        "        print(f\"Using OCR for: {pdf_path}\")\n",
        "        return self._extract_with_ocr(pdf_path, metadata, dpi, use_confidence)\n",
        "\n",
        "    def _extract_native_pdf(self, pdf_path: str, metadata: Dict):\n",
        "        reader = PdfReader(pdf_path)\n",
        "        extracted = []\n",
        "        for page_num, page in enumerate(reader.pages, 1):\n",
        "            text = page.extract_text() or ''\n",
        "            if text.strip():\n",
        "                extracted.append(ExtractedText(\n",
        "                    text=self._clean_text(text),\n",
        "                    source_file=pdf_path,\n",
        "                    grade=metadata['grade'],\n",
        "                    subject=metadata['subject'],\n",
        "                    language=metadata['language'],\n",
        "                    page_num=page_num,\n",
        "                    extraction_method='native'\n",
        "                ))\n",
        "        return extracted\n",
        "\n",
        "    def _ocr_page(self, page_tuple, lang_code, use_confidence):\n",
        "        page_num, image, source_file, metadata = page_tuple\n",
        "        text = pytesseract.image_to_string(image, lang=lang_code, config=self.tesseract_config)\n",
        "        avg_confidence = 1.0\n",
        "\n",
        "        if use_confidence:\n",
        "            data = pytesseract.image_to_data(image, lang=lang_code, output_type='dict')\n",
        "            confidences = [int(conf) for conf in data['conf'] if conf != '-1']\n",
        "            avg_confidence = sum(confidences)/len(confidences)/100.0 if confidences else 0\n",
        "\n",
        "        print(f\"✅ Processed page {page_num} of {metadata['subject']} ({metadata['language']})\")\n",
        "        return ExtractedText(\n",
        "            text=self._clean_text(text),\n",
        "            source_file=source_file,\n",
        "            grade=metadata['grade'],\n",
        "            subject=metadata['subject'],\n",
        "            language=metadata['language'],\n",
        "            page_num=page_num,\n",
        "            extraction_method='ocr',\n",
        "            confidence=avg_confidence\n",
        "        )\n",
        "\n",
        "    def _extract_with_ocr(self, pdf_path: str, metadata: Dict, dpi: int=200, use_confidence: bool=False):\n",
        "        images = convert_from_path(pdf_path, dpi=dpi)\n",
        "        lang_code = self._get_tesseract_lang(metadata['language'])\n",
        "        page_tuples = [(i+1, img, pdf_path, metadata) for i, img in enumerate(images)]\n",
        "\n",
        "        extracted = []\n",
        "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "            for result in executor.map(lambda args: self._ocr_page(args, lang_code, use_confidence), page_tuples):\n",
        "                extracted.append(result)\n",
        "        return extracted\n",
        "\n",
        "    def _get_tesseract_lang(self, language: str) -> str:\n",
        "        lang_map = {'english':'eng', 'hindi':'hin', 'urdu':'urd'}\n",
        "        return lang_map.get(language.lower(), 'eng')\n",
        "\n",
        "    def _clean_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\.\\,\\?\\!\\:\\;\\-\\(\\)]','',text)\n",
        "        return text.strip()\n",
        "\n",
        "    def save_extracted_data(self, extracted: List[ExtractedText], output_path: str):\n",
        "        data_dict = [asdict(e) for e in extracted]\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data_dict, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"✓ Saved {len(extracted)} pages to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ CELL 3: Process PDFs ============\n",
        "from tqdm import tqdm\n",
        "\n",
        "ocr_service = OPEAOCRService()\n",
        "\n",
        "pdf_files = [\n",
        "    {'path':'/content/science.pdf','metadata':{'grade':6,'subject':'science','language':'english'}},\n",
        "    {'path':'/content/Vigyan.pdf','metadata':{'grade':6,'subject':'science','language':'hindi'}}\n",
        "]\n",
        "\n",
        "for pdf_info in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
        "    pdf_path = pdf_info['path']\n",
        "    metadata = pdf_info['metadata']\n",
        "\n",
        "    extracted = ocr_service.extract_from_pdf(pdf_path, metadata, dpi=200, use_confidence=False)\n",
        "\n",
        "    output_filename = f\"{metadata['grade']}_{metadata['subject']}_{metadata['language']}_extracted.json\"\n",
        "    output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "    ocr_service.save_extracted_data(extracted, output_path)\n",
        "\n",
        "print(\"\\n✅ OCR extraction completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ApRRpuuITg",
        "outputId": "e13f1ecf-f6c4-42bd-94b0-53fb887e3ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using OCR for: /content/science.pdf\n",
            "✅ Processed page 4 of science (english)\n",
            "✅ Processed page 1 of science (english)\n",
            "✅ Processed page 6 of science (english)\n",
            "✅ Processed page 5 of science (english)\n",
            "✅ Processed page 2 of science (english)\n",
            "✅ Processed page 7 of science (english)\n",
            "✅ Processed page 3 of science (english)\n",
            "✅ Processed page 9 of science (english)\n",
            "✅ Processed page 11 of science (english)\n",
            "✅ Processed page 8 of science (english)\n",
            "✅ Processed page 10 of science (english)\n",
            "✅ Processed page 12 of science (english)\n",
            "✅ Processed page 15 of science (english)\n",
            "✅ Processed page 13 of science (english)\n",
            "✅ Processed page 14 of science (english)\n",
            "✅ Processed page 17 of science (english)\n",
            "✅ Processed page 16 of science (english)\n",
            "✅ Processed page 18 of science (english)\n",
            "✅ Processed page 21 of science (english)\n",
            "✅ Processed page 19 of science (english)\n",
            "✅ Processed page 22 of science (english)\n",
            "✅ Processed page 20 of science (english)\n",
            "✅ Processed page 23 of science (english)\n",
            "✅ Processed page 24 of science (english)\n",
            "✅ Processed page 25 of science (english)\n",
            "✅ Processed page 26 of science (english)\n",
            "✅ Processed page 28 of science (english)\n",
            "✅ Processed page 27 of science (english)\n",
            "✅ Processed page 30 of science (english)\n",
            "✅ Processed page 31 of science (english)\n",
            "✅ Processed page 29 of science (english)\n",
            "✅ Processed page 32 of science (english)\n",
            "✅ Processed page 33 of science (english)\n",
            "✅ Processed page 34 of science (english)\n",
            "✅ Processed page 35 of science (english)\n",
            "✅ Processed page 37 of science (english)\n",
            "✅ Processed page 36 of science (english)\n",
            "✅ Processed page 38 of science (english)\n",
            "✅ Processed page 39 of science (english)\n",
            "✅ Processed page 40 of science (english)\n",
            "✅ Processed page 41 of science (english)\n",
            "✅ Processed page 43 of science (english)\n",
            "✅ Processed page 44 of science (english)\n",
            "✅ Processed page 42 of science (english)\n",
            "✅ Processed page 45 of science (english)\n",
            "✅ Processed page 47 of science (english)\n",
            "✅ Processed page 48 of science (english)\n",
            "✅ Processed page 46 of science (english)\n",
            "✅ Processed page 52 of science (english)\n",
            "✅ Processed page 50 of science (english)\n",
            "✅ Processed page 51 of science (english)\n",
            "✅ Processed page 49 of science (english)\n",
            "✅ Processed page 54 of science (english)\n",
            "✅ Processed page 53 of science (english)\n",
            "✅ Processed page 56 of science (english)\n",
            "✅ Processed page 55 of science (english)\n",
            "✅ Processed page 57 of science (english)\n",
            "✅ Processed page 58 of science (english)\n",
            "✅ Processed page 59 of science (english)\n",
            "✅ Processed page 60 of science (english)\n",
            "✅ Processed page 61 of science (english)\n",
            "✅ Processed page 62 of science (english)\n",
            "✅ Processed page 63 of science (english)\n",
            "✅ Processed page 64 of science (english)\n",
            "✅ Processed page 65 of science (english)\n",
            "✅ Processed page 66 of science (english)\n",
            "✅ Processed page 67 of science (english)\n",
            "✅ Processed page 68 of science (english)\n",
            "✅ Processed page 69 of science (english)\n",
            "✅ Processed page 70 of science (english)\n",
            "✅ Processed page 71 of science (english)\n",
            "✅ Processed page 72 of science (english)\n",
            "✅ Processed page 74 of science (english)\n",
            "✅ Processed page 73 of science (english)\n",
            "✅ Processed page 75 of science (english)\n",
            "✅ Processed page 76 of science (english)\n",
            "✅ Processed page 78 of science (english)\n",
            "✅ Processed page 77 of science (english)\n",
            "✅ Processed page 79 of science (english)\n",
            "✅ Processed page 81 of science (english)\n",
            "✅ Processed page 82 of science (english)\n",
            "✅ Processed page 80 of science (english)\n",
            "✅ Processed page 83 of science (english)\n",
            "✅ Processed page 84 of science (english)\n",
            "✅ Processed page 85 of science (english)\n",
            "✅ Processed page 86 of science (english)\n",
            "✅ Processed page 87 of science (english)\n",
            "✅ Processed page 89 of science (english)\n",
            "✅ Processed page 88 of science (english)\n",
            "✅ Processed page 91 of science (english)\n",
            "✅ Processed page 90 of science (english)\n",
            "✅ Processed page 92 of science (english)\n",
            "✅ Processed page 95 of science (english)\n",
            "✅ Processed page 94 of science (english)\n",
            "✅ Processed page 93 of science (english)\n",
            "✅ Processed page 96 of science (english)\n",
            "✅ Processed page 97 of science (english)\n",
            "✅ Processed page 99 of science (english)\n",
            "✅ Processed page 98 of science (english)\n",
            "✅ Processed page 100 of science (english)\n",
            "✅ Processed page 104 of science (english)\n",
            "✅ Processed page 101 of science (english)\n",
            "✅ Processed page 103 of science (english)\n",
            "✅ Processed page 102 of science (english)\n",
            "✅ Processed page 105 of science (english)\n",
            "✅ Processed page 106 of science (english)\n",
            "✅ Processed page 108 of science (english)\n",
            "✅ Processed page 109 of science (english)\n",
            "✅ Processed page 107 of science (english)\n",
            "✅ Processed page 110 of science (english)\n",
            "✅ Processed page 111 of science (english)\n",
            "✅ Processed page 112 of science (english)\n",
            "✅ Processed page 114 of science (english)\n",
            "✅ Processed page 113 of science (english)\n",
            "✅ Processed page 115 of science (english)\n",
            "✅ Processed page 116 of science (english)\n",
            "✅ Processed page 117 of science (english)\n",
            "✅ Processed page 118 of science (english)\n",
            "✅ Processed page 119 of science (english)\n",
            "✅ Processed page 120 of science (english)\n",
            "✅ Processed page 123 of science (english)\n",
            "✅ Processed page 124 of science (english)\n",
            "✅ Processed page 121 of science (english)\n",
            "✅ Processed page 122 of science (english)\n",
            "✅ Processed page 127 of science (english)\n",
            "✅ Processed page 125 of science (english)\n",
            "✅ Processed page 126 of science (english)\n",
            "✅ Processed page 128 of science (english)\n",
            "✅ Processed page 130 of science (english)\n",
            "✅ Processed page 129 of science (english)\n",
            "✅ Processed page 131 of science (english)\n",
            "✅ Processed page 135 of science (english)\n",
            "✅ Processed page 136 of science (english)\n",
            "✅ Processed page 134 of science (english)\n",
            "✅ Processed page 133 of science (english)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  50%|█████     | 1/2 [15:26<15:26, 926.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed page 132 of science (english)\n",
            "✓ Saved 136 pages to /content/drive/MyDrive/ncert_processed/6_science_english_extracted.json\n",
            "Using OCR for: /content/Vigyan.pdf\n",
            "✅ Processed page 4 of science (hindi)\n",
            "✅ Processed page 1 of science (hindi)\n",
            "✅ Processed page 6 of science (hindi)\n",
            "✅ Processed page 5 of science (hindi)\n",
            "✅ Processed page 2 of science (hindi)\n",
            "✅ Processed page 7 of science (hindi)\n",
            "✅ Processed page 3 of science (hindi)\n",
            "✅ Processed page 11 of science (hindi)\n",
            "✅ Processed page 12 of science (hindi)\n",
            "✅ Processed page 9 of science (hindi)\n",
            "✅ Processed page 10 of science (hindi)\n",
            "✅ Processed page 8 of science (hindi)\n",
            "✅ Processed page 13 of science (hindi)\n",
            "✅ Processed page 15 of science (hindi)\n",
            "✅ Processed page 14 of science (hindi)\n",
            "✅ Processed page 17 of science (hindi)\n",
            "✅ Processed page 16 of science (hindi)\n",
            "✅ Processed page 18 of science (hindi)\n",
            "✅ Processed page 21 of science (hindi)\n",
            "✅ Processed page 22 of science (hindi)\n",
            "✅ Processed page 19 of science (hindi)\n",
            "✅ Processed page 20 of science (hindi)\n",
            "✅ Processed page 24 of science (hindi)\n",
            "✅ Processed page 23 of science (hindi)\n",
            "✅ Processed page 25 of science (hindi)\n",
            "✅ Processed page 26 of science (hindi)\n",
            "✅ Processed page 30 of science (hindi)\n",
            "✅ Processed page 28 of science (hindi)\n",
            "✅ Processed page 27 of science (hindi)\n",
            "✅ Processed page 31 of science (hindi)\n",
            "✅ Processed page 29 of science (hindi)\n",
            "✅ Processed page 32 of science (hindi)\n",
            "✅ Processed page 33 of science (hindi)\n",
            "✅ Processed page 34 of science (hindi)\n",
            "✅ Processed page 35 of science (hindi)\n",
            "✅ Processed page 37 of science (hindi)\n",
            "✅ Processed page 36 of science (hindi)\n",
            "✅ Processed page 38 of science (hindi)\n",
            "✅ Processed page 40 of science (hindi)\n",
            "✅ Processed page 39 of science (hindi)\n",
            "✅ Processed page 41 of science (hindi)\n",
            "✅ Processed page 42 of science (hindi)\n",
            "✅ Processed page 43 of science (hindi)\n",
            "✅ Processed page 44 of science (hindi)\n",
            "✅ Processed page 45 of science (hindi)\n",
            "✅ Processed page 48 of science (hindi)\n",
            "✅ Processed page 46 of science (hindi)\n",
            "✅ Processed page 47 of science (hindi)\n",
            "✅ Processed page 50 of science (hindi)\n",
            "✅ Processed page 52 of science (hindi)\n",
            "✅ Processed page 49 of science (hindi)\n",
            "✅ Processed page 51 of science (hindi)\n",
            "✅ Processed page 54 of science (hindi)\n",
            "✅ Processed page 53 of science (hindi)\n",
            "✅ Processed page 56 of science (hindi)\n",
            "✅ Processed page 55 of science (hindi)\n",
            "✅ Processed page 57 of science (hindi)\n",
            "✅ Processed page 58 of science (hindi)\n",
            "✅ Processed page 60 of science (hindi)\n",
            "✅ Processed page 59 of science (hindi)\n",
            "✅ Processed page 61 of science (hindi)\n",
            "✅ Processed page 62 of science (hindi)\n",
            "✅ Processed page 63 of science (hindi)\n",
            "✅ Processed page 64 of science (hindi)\n",
            "✅ Processed page 65 of science (hindi)\n",
            "✅ Processed page 67 of science (hindi)\n",
            "✅ Processed page 69 of science (hindi)\n",
            "✅ Processed page 68 of science (hindi)\n",
            "✅ Processed page 66 of science (hindi)\n",
            "✅ Processed page 71 of science (hindi)\n",
            "✅ Processed page 70 of science (hindi)\n",
            "✅ Processed page 73 of science (hindi)\n",
            "✅ Processed page 72 of science (hindi)\n",
            "✅ Processed page 74 of science (hindi)\n",
            "✅ Processed page 75 of science (hindi)\n",
            "✅ Processed page 77 of science (hindi)\n",
            "✅ Processed page 76 of science (hindi)\n",
            "✅ Processed page 78 of science (hindi)\n",
            "✅ Processed page 79 of science (hindi)\n",
            "✅ Processed page 80 of science (hindi)\n",
            "✅ Processed page 81 of science (hindi)\n",
            "✅ Processed page 83 of science (hindi)\n",
            "✅ Processed page 85 of science (hindi)\n",
            "✅ Processed page 84 of science (hindi)\n",
            "✅ Processed page 82 of science (hindi)\n",
            "✅ Processed page 86 of science (hindi)\n",
            "✅ Processed page 87 of science (hindi)\n",
            "✅ Processed page 88 of science (hindi)\n",
            "✅ Processed page 89 of science (hindi)\n",
            "✅ Processed page 91 of science (hindi)\n",
            "✅ Processed page 90 of science (hindi)\n",
            "✅ Processed page 92 of science (hindi)\n",
            "✅ Processed page 94 of science (hindi)\n",
            "✅ Processed page 93 of science (hindi)\n",
            "✅ Processed page 95 of science (hindi)\n",
            "✅ Processed page 96 of science (hindi)\n",
            "✅ Processed page 97 of science (hindi)\n",
            "✅ Processed page 98 of science (hindi)\n",
            "✅ Processed page 100 of science (hindi)\n",
            "✅ Processed page 99 of science (hindi)\n",
            "✅ Processed page 104 of science (hindi)\n",
            "✅ Processed page 101 of science (hindi)\n",
            "✅ Processed page 103 of science (hindi)\n",
            "✅ Processed page 102 of science (hindi)\n",
            "✅ Processed page 105 of science (hindi)\n",
            "✅ Processed page 106 of science (hindi)\n",
            "✅ Processed page 107 of science (hindi)\n",
            "✅ Processed page 108 of science (hindi)\n",
            "✅ Processed page 109 of science (hindi)\n",
            "✅ Processed page 110 of science (hindi)\n",
            "✅ Processed page 112 of science (hindi)\n",
            "✅ Processed page 111 of science (hindi)\n",
            "✅ Processed page 113 of science (hindi)\n",
            "✅ Processed page 114 of science (hindi)\n",
            "✅ Processed page 117 of science (hindi)\n",
            "✅ Processed page 115 of science (hindi)\n",
            "✅ Processed page 116 of science (hindi)\n",
            "✅ Processed page 118 of science (hindi)\n",
            "✅ Processed page 120 of science (hindi)\n",
            "✅ Processed page 119 of science (hindi)\n",
            "✅ Processed page 121 of science (hindi)\n",
            "✅ Processed page 122 of science (hindi)\n",
            "✅ Processed page 124 of science (hindi)\n",
            "✅ Processed page 125 of science (hindi)\n",
            "✅ Processed page 123 of science (hindi)\n",
            "✅ Processed page 126 of science (hindi)\n",
            "✅ Processed page 127 of science (hindi)\n",
            "✅ Processed page 128 of science (hindi)\n",
            "✅ Processed page 129 of science (hindi)\n",
            "✅ Processed page 130 of science (hindi)\n",
            "✅ Processed page 133 of science (hindi)\n",
            "✅ Processed page 135 of science (hindi)\n",
            "✅ Processed page 131 of science (hindi)\n",
            "✅ Processed page 136 of science (hindi)\n",
            "✅ Processed page 132 of science (hindi)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs: 100%|██████████| 2/2 [35:06<00:00, 1053.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed page 134 of science (hindi)\n",
            "✓ Saved 136 pages to /content/drive/MyDrive/ncert_processed/6_science_hindi_extracted.json\n",
            "\n",
            "✅ OCR extraction completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ CELL 4: Quality Check ============\n",
        "# Preview one JSON\n",
        "import json\n",
        "with open(output_path, 'r', encoding='utf-8') as f:\n",
        "    sample_data = json.load(f)\n",
        "\n",
        "print(f\"Total pages extracted: {len(sample_data)}\")\n",
        "if len(sample_data) >= 5:\n",
        "    print(f\"\\nSample page (page 5):\")\n",
        "    print(f\"Text preview: {sample_data[10]['text'][:500]}...\")\n",
        "    print(f\"Extraction method: {sample_data[4]['extraction_method']}\")\n",
        "    print(f\"Confidence: {sample_data[4]['confidence']:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL8AppOfvCgV",
        "outputId": "c11af68a-0182-41e6-8825-e71c768b4d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pages extracted: 136\n",
            "\n",
            "Sample page (page 5):\n",
            "Text preview: वषय-सच आमख य अधयय  भजन क घटक  अधयय 2 वसतओ क समह बनन व अधयय 3 पदरथ क पथककरण 20 अधयय 4 पध क जनए 34 अधयय 5 शरर म गत 45 अधयय 6 सजव - वशषतए एव आवस 58 अधयय 7 गत एव दरय क मपन पव अधयय 8 परकश-छयए एव परवरतन 86 रवव079560 2023-24...\n",
            "Extraction method: ocr\n",
            "Confidence: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4XXrkXvvF6P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}