# Mistral-7B NCERT Doubt-Solver Configuration

# ============ MODEL SETTINGS ============
model:
  name: "Mistral-7B-Instruct-v0.2"
  path: "models/mistral-7b-instruct-v0.2.gguf"
  type: "GGUF"
  quantization: "Q4_K_M"
  size_gb: 4.1
  license: "Apache 2.0"

# ============ M2 MAC OPTIMIZATION ============
m2_optimization:
  metal_acceleration: true
  n_gpu_layers: 35
  n_threads: 8
  n_batch: 512
  cpu_threads_per_core: 1
  
  # Performance targets
  expected_tokens_per_sec: 15
  expected_latency_ms: 2500
  expected_memory_mb: 5500

# ============ CONTEXT & GENERATION ============
context:
  n_ctx: 2048
  n_tokens_max: 512
  
generation:
  temperature: 0.3
  top_p: 0.95
  top_k: 40
  repetition_penalty: 1.1
  
  # Grade-specific tweaks
  grade_temperature:
    5: 0.4   # Simpler language
    6: 0.3
    7: 0.3
    8: 0.25  # More technical
    9: 0.25
    10: 0.2

# ============ VECTOR DATABASE ============
vector_db:
  type: "chromadb"
  path: "./data/chroma_db"
  embedding_model: "intfloat/multilingual-e5-large"
  embedding_dim: 1024
  similarity_metric: "cosine"

retrieval:
  top_k: 5
  similarity_threshold: 0.3
  grade_filtering: true
  subject_filtering: true
  
  # Re-ranking (optional)
  reranking_enabled: false
  reranker_model: "cross-encoder/mmarco-mMiniLMv2-L12-H384-v1"

# ============ LANGUAGE SUPPORT ============
languages:
  - code: "en"
    name: "English"
    models: ["multilingual-e5-large"]
  - code: "hi"
    name: "Hindi"
    models: ["multilingual-e5-large"]
  - code: "ur"
    name: "Urdu"
    models: ["multilingual-e5-large"]

# ============ CITATION & OUTPUT ============
citations:
  enabled: true
  format: "[Source N]"
  include_page: true
  include_chapter: true

output:
  max_answer_length: 2048
  include_confidence: true
  include_citations: true
  fallback_response: "I don't know this from the NCERT textbook. Please consult your teacher or the textbook directly."

# ============ EVALUATION METRICS ============
evaluation:
  metrics:
    - "accuracy"
    - "citation_rate"
    - "relevance"
    - "latency"
  
  thresholds:
    min_accuracy: 0.75
    min_citation_rate: 0.80
    max_latency_ms: 3000

# ============ CACHING ============
caching:
  enabled: false
  cache_type: "in_memory"
  max_cache_size_mb: 500
  ttl_minutes: 60

# ============ LOGGING ============
logging:
  level: "INFO"
  file: "logs/mistral_rag.log"
  console_output: true
  log_tokens: false

# ============ BATCH PROCESSING ============
batch:
  enabled: true
  batch_size: 4
  timeout_seconds: 300
  save_interval: 10

# ============ API SETTINGS ============
api:
  host: "127.0.0.1"
  port: 8000
  workers: 1
  timeout_seconds: 30